import Mathlib.Analysis.SpecialFunctions.Exp
import Mathlib.LinearAlgebra.Matrix.Symmetric
import Mathlib.RingTheory.LocalRing.Basic
import Mathlib.Topology.GDelta.MetrizableSpace
import NeuralNetwork.TwoState
import NeuralNetwork.TSAux
import PhysLean.Thermodynamics.Temperature.Basic

set_option linter.unusedSectionVars false
set_option linter.unusedSimpArgs false
set_option linter.style.longLine false

/-!
# Zero-temperature limit for Two-state Hopfield networks with Gibbs update

This file proves convergence of this kernel to a deterministic zero-temperature
limit as `Œ≤ ‚Üí ‚àû` (equivalently, `T ‚Üí 0+`).

## Overview

- Zero-temperature limit:
  * `scale_pos f` shows `scale f > 0` for an injective order-embedding `f`.
  * `zeroTempLimitPMF p s u` is the limiting one-step kernel at `T = 0+`, which:
    - moves deterministically to `updPos` if local field is positive,
    - to `updNeg` if negative,
    - and splits 1/2‚Äì1/2 between them on a tie.
  * Main theorem:
      `gibbs_update_tends_to_zero_temp_limit f hf p s u`
    states the PMF `gibbsUpdate f p (tempOfBeta b) s u` converges (as `b ‚Üí ‚àû`)
    to `zeroTempLimitPMF p s u`, pointwise on states.

## Key definitions and lemmas

- Convergence to zero temperature:
  * `scale_pos f`: positivity of `scale f` under an injective order embedding.
  * `zeroTempLimitPMF p s u : PMF State`: the `T ‚Üí 0+` limit kernel.
  * Pointwise convergence on the only two reachable states:
      - `gibbs_update_tends_to_zero_temp_limit_apply_updPos`
      - `gibbs_update_tends_to_zero_temp_limit_apply_updNeg`
    and zero limit on any other target state
      - `gibbs_update_tends_to_zero_temp_limit_apply_other`.
  * Main PMF convergence:
      `gibbs_update_tends_to_zero_temp_limit f hf p s u`.

-/

open Finset Matrix NeuralNetwork State Constants Temperature Filter Topology
open scoped ENNReal NNReal BigOperators
open NeuralNetwork

--variable {R U œÉ : Type}
--variable {R U œÉ : Type*}
universe uR uU uœÉ

-- We can also parametrize earlier variables with these universes if desired:
variable {R : Type uR} {U : Type uU} {œÉ : Type uœÉ}

/-! ### Convergence
As Œ≤ ‚Üí ‚àû (i.e., T ‚Üí 0+), the one‚Äìsite Gibbs update PMF converges pointwise to the
zero‚Äìtemperature limit kernel, for any TwoState NN and any order-embedding f. -/

open scoped Topology Filter
open PMF Filter

namespace TwoState
/-
  Reintroduce all required instances (they were shadowed when reopening the namespace),
  so that `U` and `NN` are fixed consistently for `updPos`, `updNeg`, `Œ∏0`, etc.
-/
variable {R U œÉ : Type}
variable [Field R] [LinearOrder R] [IsStrictOrderedRing R]
variable [DecidableEq U] [Fintype U] [Nonempty U]
variable {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN]

/-- Rewrite the 1/0/1/2 piecewise expression by dropping the positive `1/kB` factor
in front of its argument. This aligns the ‚Äúzero-temperature target‚Äù with the
real-limit expression using `c0 := Œ∫ * f L`. -/
lemma sign_piecewise_rewrite_with_c0
    {F} [FunLike F R ‚Ñù]
    (f : F)
    {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN]
    (L : R) :
    let Œ∫ := scale (R:=R) (U:=U) (œÉ:=œÉ) (NN := NN) (f:=f)
    (if 0 < ((Œ∫ / kB) * (f L)) then 1
     else if ((Œ∫ / kB) * (f L)) < 0 then 0 else (1/2 : ‚Ñù))
    =
    (if 0 < (Œ∫ * (f L)) then 1
     else if (Œ∫ * (f L)) < 0 then 0 else (1/2 : ‚Ñù)) := by
  intro Œ∫
  have ha : 0 < (kB : ‚Ñù)‚Åª¬π := inv_pos.mpr kB_pos
  have hrewrite :
      ((Œ∫ / kB) * (f L)) = (kB : ‚Ñù)‚Åª¬π * (Œ∫ * (f L)) := by
    simp [div_eq_mul_inv, mul_left_comm, mul_assoc]
  have h := piecewise01half_sign_mul_left_pos
              (a := (kB : ‚Ñù)‚Åª¬π) (v := Œ∫ * (f L)) ha
  simpa [hrewrite] using h

/-- Œ∫ := scale between the two numeric states (pushed along f) is positive
    under a strictly monotone embedding and the class `m_order`. -/
lemma scale_pos
    {F} [FunLike F R ‚Ñù] [OrderHomClass F R ‚Ñù]
    (f : F) (hf : Function.Injective f)
    {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN] :
    0 < scale (R:=R) (U:=U) (œÉ:=œÉ) (NN := NN) (f:=f) := by
  -- TwoStateNeuralNetwork.m_order : m œÉ_neg < m œÉ_pos
  have h := (strictMono_of_injective_orderHom (R:=R) (f:=f) hf)
  have himg :
      f (NN.m (TwoStateNeuralNetwork.œÉ_neg (NN := NN))) <
        f (NN.m (TwoStateNeuralNetwork.œÉ_pos (NN := NN))) :=
    h (TwoStateNeuralNetwork.m_order (NN := NN))
  exact sub_pos.mpr himg

/-- One-step zero-temperature limit kernel (tie -> 1/2 mixture of updPos/updNeg). -/
noncomputable def zeroTempLimitPMF
    (p : Params NN) (s : NN.State) (u : U) : PMF NN.State :=
  let net := s.net p u
  let Œ∏   := (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u)
  if h : Œ∏ < net then
    PMF.pure (updPos (s:=s) (u:=u))
  else if h' : net < Œ∏ then
    PMF.pure (updNeg (s:=s) (u:=u))
  else
    -- tie: 1/2 ‚Äì 1/2 Bernoulli mixture
    let pHalf : ‚Ñù‚â•0 := (1/2 : ‚Ñù‚â•0)
    have hp : pHalf ‚â§ 1 := by norm_num
    PMF.bernoulli pHalf hp >>= fun b =>
      if b then PMF.pure (updPos (s:=s) (u:=u))
           else PMF.pure (updNeg (s:=s) (u:=u))

/-- Helper: the two updated states differ. -/
private lemma updPos_ne_updNeg (s : NN.State) (u : U) :
    updPos (s:=s) (u:=u) ‚â† updNeg (s:=s) (u:=u) := by
  intro h
  have := congrArg (fun st => st.act u) h
  simp [updPos, updNeg, Function.update, TwoStateNeuralNetwork.h_pos_ne_neg] at this

/-
  General limit lemmas for reals, used to analyze the zero-temperature limit.
  These are independent of the neural-network context.
-/
open Real Filter Topology Monotone

/-- As `x ‚Üí +‚àû`, `logisticProb x ‚Üí 1`. -/
lemma logisticProb_tendsto_atTop :
    Tendsto logisticProb atTop (ùìù (1 : ‚Ñù)) := by
  -- logisticProb x = 1/(1 + exp(-x)); as x‚Üí+‚àû, -x‚Üí-‚àû, so exp(-x)‚Üí0, then 1/(1+r)‚Üí1
  have hx_neg : Tendsto (fun x : ‚Ñù => -x) atTop atBot :=
    (tendsto_neg_atBot_iff).mpr tendsto_id
  have h_exp : Tendsto (fun x => Real.exp (-x)) atTop (ùìù 0) :=
    Real.tendsto_exp_atBot.comp hx_neg
  have h_cont : ContinuousAt (fun r : ‚Ñù => (1 : ‚Ñù) / (1 + r)) 0 :=
    (continuousAt_const.div (continuousAt_const.add continuousAt_id) (by norm_num))
  have h_comp :
      Tendsto (fun x => (1 : ‚Ñù) / (1 + Real.exp (-x))) atTop (ùìù ((1 : ‚Ñù) / (1 + 0))) :=
    h_cont.tendsto.comp h_exp
  unfold logisticProb
  simpa [Real.exp_zero] using h_comp

/-- As `x ‚Üí -‚àû`, `logisticProb x ‚Üí 0`. -/
lemma logisticProb_tendsto_atBot :
    Tendsto logisticProb atBot (ùìù (0 : ‚Ñù)) := by
  -- 0 ‚â§ logistic ‚â§ exp, and exp x ‚Üí 0 as x‚Üí-‚àû
  have h_le_exp : ‚àÄ x : ‚Ñù, logisticProb x ‚â§ Real.exp x := by
    intro x
    unfold logisticProb
    have hxpos : 0 < Real.exp (-x) := Real.exp_pos _
    have hz_le : Real.exp (-x) ‚â§ 1 + Real.exp (-x) := by linarith
    have : (1 : ‚Ñù) / (1 + Real.exp (-x)) ‚â§ (1 : ‚Ñù) / Real.exp (-x) :=
      one_div_le_one_div_of_le hxpos hz_le
    simpa [one_div, Real.exp_neg] using this
  refine
    tendsto_of_tendsto_of_tendsto_of_le_of_le
      (tendsto_const_nhds) (Real.tendsto_exp_atBot)
      (fun x => logisticProb_nonneg x)
      (fun x => h_le_exp x)

/-- As `T ‚Üí 0+`, if `c > 0` then `logisticProb (c/T) ‚Üí 1`. -/
lemma tendsto_logistic_scaled_of_pos {c : ‚Ñù} (hc : 0 < c) :
    Tendsto (fun T : ‚Ñù => logisticProb (c / T)) (ùìù[>] (0 : ‚Ñù)) (ùìù (1 : ‚Ñù)) :=
  logisticProb_tendsto_atTop.comp (tendsto_c_div_atTop_of_pos hc)

/-- As `T ‚Üí 0+`, if `c < 0` then `logisticProb (c/T) ‚Üí 0`. -/
lemma tendsto_logistic_scaled_of_neg {c : ‚Ñù} (hc : c < 0) :
    Tendsto (fun T : ‚Ñù => logisticProb (c / T)) (ùìù[>] (0 : ‚Ñù)) (ùìù (0 : ‚Ñù)) :=
  logisticProb_tendsto_atBot.comp (tendsto_c_div_atBot_of_neg hc)

/-- As `T ‚Üí 0+`, if `c = 0` then `logisticProb (c/T)` is constantly `1/2`. -/
lemma tendsto_logistic_scaled_of_eq_zero {c : ‚Ñù} (hc : c = 0) :
    Tendsto (fun T : ‚Ñù => logisticProb (c / T)) (ùìù[>] (0 : ‚Ñù)) (ùìù ((1 : ‚Ñù) / 2)) := by
  have : (fun T : ‚Ñù => logisticProb (c / T)) =·∂†[ùìù[>] (0 : ‚Ñù)] fun _ => 1 / 2 := by
    filter_upwards [self_mem_nhdsWithin] with T _
    simp [logisticProb, hc, Real.exp_zero, one_add_one_eq_two]
  exact (tendsto_congr' this).mpr tendsto_const_nhds

/-- As `T ‚Üí 0+`, `logisticProb (c / T)` tends to `1` if `c > 0`, to `0` if `c < 0`,
and to `1/2` if `c = 0`. -/
lemma tendsto_logistic_scaled
    (c : ‚Ñù) :
    Tendsto (fun T : ‚Ñù => logisticProb (c / T)) (nhdsWithin 0 (Set.Ioi 0))
      (ùìù (if 0 < c then 1 else if c < 0 then 0 else 1/2)) := by
  by_cases hcpos : 0 < c
  ¬∑ simpa [hcpos] using (tendsto_logistic_scaled_of_pos (c:=c) hcpos)
  ¬∑ by_cases hcneg : c < 0
    ¬∑ have := tendsto_logistic_scaled_of_neg (c:=c) hcneg
      simpa [hcpos, hcneg] using this
    ¬∑ have hc0 : c = 0 := le_antisymm (le_of_not_gt hcpos) (le_of_not_gt hcneg)
      simpa [hcpos, hcneg, hc0] using (tendsto_logistic_scaled_of_eq_zero (c:=c) hc0)

/-- On ‚Ñù‚â•0: as `b ‚Üí ‚àû`, `logisticProb (c * b) ‚Üí 1/0/1/2` depending on the sign of `c`. -/
lemma tendsto_logistic_const_mul_coeNNReal
    (c : ‚Ñù) :
    Tendsto (fun b : ‚Ñù‚â•0 => logisticProb (c * (b : ‚Ñù))) atTop
      (ùìù (if 0 < c then 1 else if c < 0 then 0 else 1/2)) := by
  have h_coe : Tendsto (fun b : ‚Ñù‚â•0 => (b : ‚Ñù)) atTop atTop := by
    refine (Filter.tendsto_atTop_atTop).2 ?_
    intro M
    refine ‚ü®‚ü®max 0 (M + 1), by have : 0 ‚â§ max 0 (M + 1) := le_max_left _ _; exact this‚ü©, ?_‚ü©
    intro b hb
    have hBR : (max 0 (M + 1) : ‚Ñù) ‚â§ (b : ‚Ñù) := by exact_mod_cast hb
    have hM1 : (M + 1 : ‚Ñù) ‚â§ (b : ‚Ñù) := le_trans (le_max_right _ _) hBR
    have : (M : ‚Ñù) ‚â§ (b : ‚Ñù) := by linarith
    exact this
  by_cases hcpos : 0 < c
  ¬∑ have hmul := tendsto_mul_const_atTop_atTop_of_pos (c:=c) hcpos
    simpa [hcpos, Function.comp] using
      logisticProb_tendsto_atTop.comp (hmul.comp h_coe)
  ¬∑ by_cases hcneg : c < 0
    ¬∑ have hmul := tendsto_mul_const_atTop_atBot_of_neg (c:=c) hcneg
      simpa [hcpos, hcneg, Function.comp] using
        logisticProb_tendsto_atBot.comp (hmul.comp h_coe)
    ¬∑ have hc0 : c = 0 := le_antisymm (le_of_not_gt hcpos) (le_of_not_gt hcneg)
      have hconst :
          (fun b : ‚Ñù‚â•0 => logisticProb (c * (b : ‚Ñù))) = fun _ => (1/2 : ‚Ñù) := by
        funext b; simp [hc0, logisticProb, Real.exp_zero, one_add_one_eq_two]
      aesop

/-- Real-valued probability limit P(T) for our model as T ‚Üí 0+. -/
lemma tendsto_probPos_at_zero
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù] [OrderHomClass F R ‚Ñù]
    (f : F) (_ : Function.Injective f)
    (p : Params NN) (s : NN.State) (u : U) :
    let L : R := (s.net p u) - (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u)
    Tendsto (fun T : ‚Ñù => probPos (NN := NN) f p ‚ü®Real.toNNReal T‚ü© s u)
      (nhdsWithin 0 (Set.Ioi 0))
      (ùìù (let Œ∫ := scale (NN := NN) (f:=f); let c := (Œ∫ / kB) * (f L);
          if 0 < c then 1 else if c < 0 then 0 else 1/2)) := by
  intro L
  have h_event :
      (fun T : ‚Ñù => probPos (NN := NN) f p ‚ü®Real.toNNReal T‚ü© s u)
        =·∂†[nhdsWithin 0 (Set.Ioi 0)]
      (fun T : ‚Ñù =>
        logisticProb (((scale (NN := NN) (f:=f)) / kB) * (f L) / T)) := by
    filter_upwards [self_mem_nhdsWithin] with T hTpos
    have hT0 : 0 ‚â§ T := le_of_lt hTpos
    have : (Œ≤ ‚ü®Real.toNNReal T‚ü© : ‚Ñù) = 1 / (kB * T) := by
      simp [Temperature.Œ≤, Temperature.toReal, Real.toNNReal_of_nonneg hT0, one_div]
    unfold probPos
    simp [this, logisticProb, mul_comm, mul_assoc, div_eq_mul_inv]
    simp_all only [Set.mem_Ioi, one_div, mul_inv_rev, map_sub, true_or, L]
  have hlim :
      Tendsto (fun T : ‚Ñù =>
        logisticProb (((scale (NN := NN) (f:=f)) / kB) * (f L) / T))
        (nhdsWithin 0 (Set.Ioi 0))
        (ùìù (let Œ∫ := scale (NN := NN) (f:=f); let c := (Œ∫ / kB) * (f L);
             if 0 < c then 1 else if c < 0 then 0 else 1/2)) :=
    tendsto_logistic_scaled _
  exact (tendsto_congr' h_event).mpr hlim

open PMF

/-- Pointwise evaluation at `updPos`: exact equality with `probPos`. (Fixed bernoulli usage.) -/
lemma gibbsUpdate_apply_updPos
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù]
    (f : F) (p : Params NN) (T : Temperature) (s : NN.State) (u : U) :
    (gibbsUpdate (NN := NN) f p T s u) (updPos (s:=s) (u:=u))
      = ENNReal.ofReal (probPos (NN := NN) f p T s u) := by
  unfold gibbsUpdate
  set pPos : ‚Ñù := probPos (NN := NN) f p T s u
  have hPos_nonneg : 0 ‚â§ pPos := probPos_nonneg (NN := NN) f p T s u
  have hPos_le_one : pPos ‚â§ 1 := probPos_le_one (NN := NN) f p T s u
  set q : ‚Ñù‚â•0 := ‚ü®pPos, hPos_nonneg‚ü©
  have hq_le : q ‚â§ 1 := by
    exact_mod_cast hPos_le_one
  have hne := updPos_ne_updNeg (s:=s) (u:=u)
  have hcoe : (q : ‚Ñù‚â•0‚àû) = ENNReal.ofReal pPos := by
    simp [q, pPos, ENNReal.ofReal]
    simp_all only [ne_eq, pPos, q]
    ext : 1
    simp_all only [NNReal.coe_mk, coe_toNNReal', left_eq_sup]
    exact hPos_nonneg
  simp [q, hcoe, PMF.bernoulli_bind_pure_apply_left_of_ne (Œ±:=NN.State) hq_le hne,
        pPos]

/-- Pointwise evaluation at `updNeg`: exact equality with `1 - probPos`. -/
lemma gibbsUpdate_apply_updNeg
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù]
    (f : F) (p : Params NN) (T : Temperature) (s : NN.State) (u : U) :
    (gibbsUpdate (NN := NN) f p T s u) (updNeg (s:=s) (u:=u))
      = ENNReal.ofReal (1 - probPos (NN := NN) f p T s u) := by
  unfold gibbsUpdate
  set pPos : ‚Ñù := probPos (NN := NN) f p T s u
  have hPos_nonneg : 0 ‚â§ pPos := probPos_nonneg (NN := NN) f p T s u
  have hPos_le_one : pPos ‚â§ 1 := probPos_le_one (NN := NN) f p T s u
  set q : ‚Ñù‚â•0 := ‚ü®pPos, hPos_nonneg‚ü©
  have hq_le : q ‚â§ 1 := by
    exact_mod_cast hPos_le_one
  have hne := updPos_ne_updNeg (s:=s) (u:=u)
  have hcoe : (q : ‚Ñù‚â•0‚àû) = ENNReal.ofReal pPos := by
    simp [q, pPos, ENNReal.ofReal]
    simp_all only [ne_eq, pPos, q]
    ext : 1
    simp_all only [NNReal.coe_mk, coe_toNNReal', left_eq_sup]
    exact hPos_nonneg
  have hEval :
      ((PMF.bernoulli q hq_le) >>= fun b =>
        if b then PMF.pure (updPos (s:=s) (u:=u)) else PMF.pure (updNeg (s:=s) (u:=u)))
        (updNeg (s:=s) (u:=u))
      = ((1 : ‚Ñù‚â•0) - q : ‚Ñù‚â•0) :=
    PMF.bernoulli_bind_pure_apply_right_of_ne (Œ±:=NN.State) hq_le hne
  have h_sub :
      ((1 : ‚Ñù‚â•0) - q : ‚Ñù‚â•0) = ‚ü®1 - pPos, by
        have : 0 ‚â§ 1 - pPos := sub_nonneg.mpr hPos_le_one
        simpa [q] using this‚ü© := by
          simp_all only [ne_eq, not_false_eq_true, bernoulli_bind_pure_apply_right_of_ne,
            ENNReal.coe_sub, ENNReal.coe_one, q, pPos]
          simp_all only [q, pPos]
          ext : 1
          simp_all only [NNReal.coe_sub, NNReal.coe_one, NNReal.coe_mk]
  have hENN :
      ((1 : ‚Ñù‚â•0) - (q : ‚Ñù‚â•0) : ‚Ñù‚â•0‚àû)
        = ENNReal.ofReal (1 - pPos) := by
    have h1 : 0 ‚â§ 1 - pPos := sub_nonneg.mpr hPos_le_one
    simp [q, ENNReal.ofReal, pPos]
    rfl
  simpa [q, h_sub, hENN, pPos]

/-- Eventual equality rewriting Gibbs mass at updPos along Œ≤ ‚Üí ‚àû to ENNReal.ofReal (probPos at T). -/
lemma eventually_eval_updPos_eq_ofReal_probPos
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù]
    (f : F) (p : Params NN) (s : NN.State) (u : U) :
    (fun b : ‚Ñù‚â•0 => (gibbsUpdate (NN := NN) f p (Temperature.ofŒ≤ b) s u) (updPos (s:=s) (u:=u)))
      =·∂†[atTop]
    (fun b : ‚Ñù‚â•0 => ENNReal.ofReal (probPos (NN := NN) f p (Temperature.ofŒ≤ b) s u)) := by
  refine Filter.Eventually.of_forall ?_
  intro b; simp [gibbsUpdate_apply_updPos]

/-- Eventual equality rewriting Gibbs mass at updNeg along Œ≤ ‚Üí ‚àû to ENNReal.ofReal (1 - probPos). -/
lemma eventually_eval_updNeg_eq_ofReal_one_sub_probPos
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù]
    (f : F) (p : Params NN) (s : NN.State) (u : U) :
    (fun b : ‚Ñù‚â•0 => (gibbsUpdate (NN := NN) f p (Temperature.ofŒ≤ b) s u) (updNeg (s:=s) (u:=u)))
      =·∂†[atTop]
    (fun b : ‚Ñù‚â•0 => ENNReal.ofReal (1 - probPos (NN := NN) f p (Temperature.ofŒ≤ b) s u)) := by
  refine Filter.Eventually.of_forall ?_
  intro b; simp [gibbsUpdate_apply_updNeg]

lemma zeroTempLimitPMF_updPos_eval_pos
    (p : Params NN) (s : NN.State) (u : U)
    {net Œ∏ : R} (h : Œ∏ < net)
    (hnet : net = s.net p u)
    (hŒ∏ : Œ∏ = (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u)) :
    (zeroTempLimitPMF (NN := NN) p s u) (updPos (s:=s) (u:=u)) = 1 := by
  subst hnet; subst hŒ∏
  unfold zeroTempLimitPMF
  simp [h]

lemma zeroTempLimitPMF_updPos_eval_neg
    (p : Params NN) (s : NN.State) (u : U)
    {net Œ∏ : R} (h : net < Œ∏)
    (hnet : net = s.net p u)
    (hŒ∏ : Œ∏ = (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u)) :
    (zeroTempLimitPMF (NN := NN) p s u) (updPos (s:=s) (u:=u)) = 0 := by
  subst hnet; subst hŒ∏
  unfold zeroTempLimitPMF
  have h‚ÇÅ : ¬¨ ((p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u) < s.net p u) :=
    not_lt.mpr h.le
  have hne : updPos (s:=s) (u:=u) ‚â† updNeg (s:=s) (u:=u) :=
    updPos_ne_updNeg (s:=s) (u:=u)
  simp [h, h‚ÇÅ, hne]

lemma zeroTempLimitPMF_updPos_eval_tie
    (p : Params NN) (s : NN.State) (u : U)
    {net Œ∏ : R} (h : net = Œ∏)
    (hnet : net = s.net p u)
    (hŒ∏ : Œ∏ = (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u)) :
    (zeroTempLimitPMF (NN := NN) p s u) (updPos (s:=s) (u:=u)) = (1/2 : ‚Ñù‚â•0‚àû) := by
  subst hnet; subst hŒ∏
  have h' : s.net p u = (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u) := h
  unfold zeroTempLimitPMF
  have hlt1 : ¬¨ ((p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u) < s.net p u) := by
    simp [h']
  have hlt2 : ¬¨ (s.net p u < (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u)) := by
    simp [h']
  have hne : updPos (s:=s) (u:=u) ‚â† updNeg (s:=s) (u:=u) :=
    updPos_ne_updNeg (s:=s) (u:=u)
  have hp : ( (1/2 : ‚Ñù‚â•0) ‚â§ 1 ) := by norm_num
  simp [h', hne]

variable {F} [Field R] [LinearOrder R] [IsStrictOrderedRing R]
variable [DecidableEq U] [Fintype U] [Nonempty U]
variable {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN]
variable [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù] [OrderHomClass F R ‚Ñù]

/-- Core algebra: under Œ∏ < net, the scaled difference is positive. -/
lemma pos_of_theta_lt_net
    (f : F) (hf : Function.Injective f)
    (net Œ∏ : R) (h : Œ∏ < net) :
    0 < ((scale (NN := NN) (f:=f)) / kB) * (f net - f Œ∏) := by
  have hŒ∫ : 0 < scale (NN := NN) (f:=f) :=
    scale_pos (R:=R) (U:=U) (œÉ:=œÉ) (NN := NN) (f:=f) hf
  have hŒ∫div : 0 < scale (NN := NN) (f:=f) / kB := div_pos hŒ∫ kB_pos
  have hsub : 0 < net - Œ∏ := sub_pos.mpr h
  have hfsub : 0 < f (net - Œ∏) := map_pos_of_pos (R:=R) (f:=f) hf hsub
  simpa [map_sub f] using mul_pos hŒ∫div hfsub

/-- Core algebra: under net<Œ∏, the scaled difference is negative. -/
lemma neg_of_net_lt_theta
    (f : F) (hf : Function.Injective f)
    (net Œ∏ : R) (h : net < Œ∏) :
    ((scale (NN := NN) (f:=f)) / kB) * (f net - f Œ∏) < 0 := by
  have hŒ∫ : 0 < scale (NN := NN) (f:=f) :=
    scale_pos (R:=R) (U:=U) (œÉ:=œÉ) (NN := NN) (f:=f) hf
  have hŒ∫div : 0 < scale (NN := NN) (f:=f) / kB := div_pos hŒ∫ kB_pos
  have hsub : net - Œ∏ < 0 := sub_lt_zero.mpr h
  have hfsub : f (net - Œ∏) < 0 := map_neg_of_neg (R:=R) (f:=f) hf hsub
  simpa [map_sub f] using mul_neg_of_pos_of_neg hŒ∫div hfsub

/-- Tie algebra: equality case. -/
lemma zero_of_net_eq_theta
    (f : F) (net Œ∏ : R) (h : net = Œ∏) :
    ((scale (NN := NN) (f:=f)) / kB) * (f net - f Œ∏) = 0 := by
  simp [h]

lemma zeroTemp_target_updPos_as_ofReal_sign
    (f : F) (hf : Function.Injective f)
    (p : Params NN) (s : NN.State) (u : U) :
    let net := s.net p u
    let Œ∏   := (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u)
    (zeroTempLimitPMF (NN := NN) p s u) (updPos (s:=s) (u:=u)) =
      ENNReal.ofReal
        (if 0 < ((scale (NN := NN) (f:=f)) / kB) * (f net - f Œ∏)
         then 1
         else if ((scale (NN := NN) (f:=f)) / kB) * (f net - f Œ∏) < 0
              then 0
              else (1/2 : ‚Ñù)) := by
  intro net Œ∏
  rcases lt_trichotomy Œ∏ net with hlt | heq | hgt
  ¬∑ -- Case 1: Œ∏ < net (positive local field)
    have h_lhs := zeroTempLimitPMF_updPos_eval_pos (NN := NN) p s u hlt rfl rfl
    have h_rhs_arg := pos_of_theta_lt_net (NN := NN) (f:=f) hf net Œ∏ hlt
    simp [h_lhs, h_rhs_arg]
  ¬∑ -- Case 2: Œ∏ = net (tie)
    have h_lhs := zeroTempLimitPMF_updPos_eval_tie (NN := NN) p s u heq.symm rfl rfl
    have h_rhs_arg := zero_of_net_eq_theta (NN := NN) (f:=f) net Œ∏ heq.symm
    have hhalf : ENNReal.ofReal ((2 : ‚Ñù)‚Åª¬π) = (2 : ‚Ñù‚â•0‚àû)‚Åª¬π := by
      rw [ENNReal.ofReal_inv_of_pos (by norm_num : (0 : ‚Ñù) < 2)]
      simp
    simp [h_lhs, h_rhs_arg]; ring_nf; aesop
  ¬∑ -- Case 3: net < Œ∏ (negative local field)
    have h_lhs := zeroTempLimitPMF_updPos_eval_neg (NN := NN) p s u hgt rfl rfl
    have h_rhs_arg := neg_of_net_lt_theta (NN := NN) (f:=f) hf net Œ∏ hgt
    simp [h_lhs, h_rhs_arg, not_lt.mpr h_rhs_arg.le]

lemma zeroTemp_target_updNeg_as_ofReal_one_sub_sign_pos
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù] [OrderHomClass F R ‚Ñù]
    (f : F) (hf : Function.Injective f)
    (p : Params NN) (s : NN.State) (u : U)
    {net Œ∏ : R} (hpos : Œ∏ < net)
    (hnet : net = s.net p u) (hŒ∏ : Œ∏ =
      (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u)) :
    (zeroTempLimitPMF (NN := NN) p s u) (updNeg (s:=s) (u:=u)) =
      ENNReal.ofReal
        (1 - (if 0 < ((scale (NN := NN) (f:=f)) / kB) * f (net - Œ∏) then 1
              else if ((scale (NN := NN) (f:=f)) / kB) * f (net - Œ∏) < 0 then 0
              else (1/2 : ‚Ñù))) := by
  subst hnet; subst hŒ∏
  have hLpos : 0 < (s.net p u) - (p.Œ∏ u).get _ := sub_pos.mpr hpos
  have hfpos : 0 < f ((s.net p u) - (p.Œ∏ u).get _) :=
    map_pos_of_pos (R:=R) (f:=f) hf hLpos
  have hŒ∫pos : 0 < (scale (NN := NN) (f:=f)) / kB :=
    div_pos (scale_pos (R:=R) (U:=U) (œÉ:=œÉ) (NN := NN) (f:=f) hf) kB_pos
  have hprod : 0 <
      ((scale (NN := NN) (f:=f)) / kB) * f ((s.net p u) - (p.Œ∏ u).get _) :=
    mul_pos hŒ∫pos hfpos
  have hne := updPos_ne_updNeg (s:=s) (u:=u)
  have hnot : ¬¨ s.net p u < (p.Œ∏ u).get _ := not_lt.mpr hpos.le
  simp [zeroTempLimitPMF, hpos]
  simp_all only [sub_pos, map_sub, mul_pos_iff_of_pos_left, ne_eq, not_lt, ‚ÜìreduceIte, sub_self, ENNReal.ofReal_zero,
    ite_eq_right_iff, one_ne_zero, imp_false]
  apply Aesop.BuiltinRules.not_intro
  intro a
  simp_all only [not_true_eq_false]

/-! ### Helpers for the `updNeg` zero-temperature targets -/

open scoped ENNReal

/-- Abbreviation: the scaled, pushed-along local-field appearing in the RHS
     of the `updNeg` lemmas. -/
noncomputable def scaledField (f : F) (p : Params NN) (s : NN.State) (u : U) : ‚Ñù :=
  let Œ∫ := scale  (NN := NN) (f:=f)
  let L := (s.net p u) - (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u)
  (Œ∫ / kB) * f L

/-- If the scaled field is negative, the inner {1,0,¬Ω} collapses to `0`. -/
lemma scaledField_neg_imp_piece_zero
    (_ : F) {x : ‚Ñù} (hx : x < (0 : ‚Ñù)) :
    (if 0 < x then 1 else if x < 0 then 0 else (1/2 : ‚Ñù)) = 0 := by
  have : ¬¨ 0 < x := not_lt.mpr hx.le
  simp [this, hx]

/-- If the scaled field is exactly `0`, the inner {1,0,¬Ω} collapses to `¬Ω`. -/
lemma scaledField_zero_imp_piece_half
    {x : ‚Ñù} (hx : x = 0) :
    (if 0 < x then 1 else if x < 0 then 0 else (1/2 : ‚Ñù)) = (1/2 : ‚Ñù) := by
  simp [hx]

/-!  Focused evaluation lemmas for zeroTempLimitPMF at `updNeg`.  -/
lemma zeroTempLimitPMF_updNeg_eval_neg
    (p : Params NN) (s : NN.State) (u : U)
    {net Œ∏ : R} (hneg : net < Œ∏)
    (hnet : net = s.net p u)
    (hŒ∏ : Œ∏ = (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u)) :
    (zeroTempLimitPMF (NN := NN) p s u) (updNeg (s:=s) (u:=u)) = 1 := by
  subst hnet; subst hŒ∏
  unfold zeroTempLimitPMF
  have : ¬¨ ((p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u) < s.net p u) :=
    not_lt.mpr hneg.le
  simp [this, hneg]

lemma zeroTempLimitPMF_updNeg_eval_pos
    (p : Params NN) (s : NN.State) (u : U)
    {net Œ∏ : R} (hpos : Œ∏ < net)
    (hnet : net = s.net p u)
    (hŒ∏ : Œ∏ = (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u)) :
    (zeroTempLimitPMF (NN := NN) p s u) (updNeg (s:=s) (u:=u)) = 0 := by
  subst hnet; subst hŒ∏
  unfold zeroTempLimitPMF
  have hne : updNeg (NN := NN) (s:=s) (u:=u) ‚â† updPos (NN := NN) (s:=s) (u:=u) := by
    have h := updPos_ne_updNeg (NN := NN) (s:=s) (u:=u)
    simpa [ne_comm] using h
  simp [hpos, hne]

lemma zeroTempLimitPMF_updNeg_eval_tie
    (p : Params NN) (s : NN.State) (u : U)
    {net Œ∏ : R} (htie : net = Œ∏)
    (hnet : net = s.net p u)
    (hŒ∏ : Œ∏ = (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u)) :
    (zeroTempLimitPMF (NN := NN) p s u) (updNeg (s:=s) (u:=u)) = (1/2 : ‚Ñù‚â•0‚àû) := by
  subst hnet; subst hŒ∏
  unfold zeroTempLimitPMF
  have h1 : ¬¨ ((p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u) <
              s.net p u) := by simp [htie]
  have h2 : ¬¨ (s.net p u <
              (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u)) := by simp [htie]
  have hne := updPos_ne_updNeg (s:=s) (u:=u)
  have hp : ((1/2 : ‚Ñù‚â•0) ‚â§ 1) := by norm_num
  simp [htie, hne]

lemma zeroTemp_target_updNeg_as_ofReal_one_sub_sign_neg
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù] [OrderHomClass F R ‚Ñù]
    (f : F) (hf : Function.Injective f)
    (p : Params NN) (s : NN.State) (u : U)
    {net Œ∏ : R} (hneg : net < Œ∏)
    (hnet : net = s.net p u)
    (hŒ∏ : Œ∏ = (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u)) :
    (zeroTempLimitPMF (NN := NN) p s u) (updNeg (s:=s) (u:=u)) =
      ENNReal.ofReal
        (1 - (if 0 < ((scale (NN := NN) (f:=f)) / kB) * f (net - Œ∏) then 1
              else if ((scale (NN := NN) (f:=f)) / kB) * f (net - Œ∏) < 0 then 0
              else (1/2 : ‚Ñù))) := by
  have hLHS := zeroTempLimitPMF_updNeg_eval_neg (NN := NN) p s u hneg hnet hŒ∏
  subst hnet; subst hŒ∏
  let Œ∏0 := TwoStateNeuralNetwork.Œ∏0 (NN := NN) u
  let Œ∫  := scale (NN := NN) (f:=f)
  let L  : R := s.net p u - (p.Œ∏ u).get Œ∏0
  have hL_neg : L < 0 := sub_lt_zero.mpr hneg
  have hfL_neg : f L < 0 := map_neg_of_neg (R:=R) (f:=f) hf hL_neg
  have hŒ∫_pos : 0 < Œ∫ := scale_pos (R:=R) (U:=U) (œÉ:=œÉ) (NN := NN) (f:=f) hf
  have hŒ∫div_pos : 0 < Œ∫ / kB := div_pos hŒ∫_pos kB_pos
  have hprod_neg : (Œ∫ / kB) * f L < 0 := mul_neg_of_pos_of_neg hŒ∫div_pos hfL_neg
  have hPiece :
      (if 0 < (Œ∫ / kB) * f L then 1
       else if (Œ∫ / kB) * f L < 0 then 0
       else (1/2 : ‚Ñù)) = 0 :=
    scaledField_neg_imp_piece_zero f hprod_neg
  have hPiece'' :
      (if 0 < (Œ∫ / kB) * f (s.net p u - (p.Œ∏ u).get Œ∏0) then 1
       else if (Œ∫ / kB) * f (s.net p u - (p.Œ∏ u).get Œ∏0) < 0 then 0
       else (1/2 : ‚Ñù)) = 0 := by
    simpa [L] using hPiece
  have : (zeroTempLimitPMF (NN := NN) p s u) (updNeg (s:=s) (u:=u)) = 1 := hLHS
  rw [this, hPiece'']
  simp

lemma zeroTemp_target_updNeg_as_ofReal_one_sub_sign_tie
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù] [OrderHomClass F R ‚Ñù]
    (f : F) (_ : Function.Injective f) -- (hf kept for uniform signature; unused here)
    (p : Params NN) (s : NN.State) (u : U)
    {net Œ∏ : R} (htie : net = Œ∏)
    (hnet : net = s.net p u)
    (hŒ∏ : Œ∏ = (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u)) :
    (zeroTempLimitPMF (NN := NN) p s u) (updNeg (s:=s) (u:=u)) =
      ENNReal.ofReal
        (1 - (if 0 < ((scale (NN := NN) (f:=f)) / kB) * f (net - Œ∏) then 1
              else if ((scale (NN := NN) (f:=f)) / kB) * f (net - Œ∏) < 0 then 0
              else (1/2 : ‚Ñù))) := by
  have hLHS := zeroTempLimitPMF_updNeg_eval_tie (NN := NN) p s u htie hnet hŒ∏
  subst hnet; subst hŒ∏
  let Œ∏0 := TwoStateNeuralNetwork.Œ∏0 (NN := NN) u
  let Œ∫  := scale (NN := NN) (f:=f)
  let L  : R := s.net p u - (p.Œ∏ u).get Œ∏0
  have hL0 : L = 0 := by
    unfold L; simpa using (sub_eq_zero.mpr htie)
  have hPiece :
      (if 0 < (Œ∫ / kB) * f L then 1
       else if (Œ∫ / kB) * f L < 0 then 0
       else (1/2 : ‚Ñù)) = (1/2 : ‚Ñù) := by
    have : (Œ∫ / kB) * f L = 0 := by simp [hL0]
    exact scaledField_zero_imp_piece_half (x := (Œ∫ / kB) * f L) this
  have hPiece' :
      (if 0 < (Œ∫ / kB) * f (s.net p u - (p.Œ∏ u).get Œ∏0) then 1
       else if (Œ∫ / kB) * f (s.net p u - (p.Œ∏ u).get Œ∏0) < 0 then 0
       else (1/2 : ‚Ñù)) = (1/2 : ‚Ñù) := by
    simpa [L] using hPiece
  have hxArg :
      (Œ∫ / kB) * f (s.net p u - (p.Œ∏ u).get Œ∏0) = 0 := by
    simp
    simp_all only [one_div, sub_self, map_zero, mul_zero, lt_self_iff_false, ‚ÜìreduceIte, or_true,
      L, Œ∏0, Œ∫]
  have hRHS_simp :
      ENNReal.ofReal
        (1 -
          (if 0 < (Œ∫ / kB) * f (s.net p u - (p.Œ∏ u).get Œ∏0) then 1
           else if (Œ∫ / kB) * f (s.net p u - (p.Œ∏ u).get Œ∏0) < 0 then 0
           else (1/2 : ‚Ñù)))
        = (1/2 : ‚Ñù‚â•0‚àû) :=
    ENNReal.ofReal_one_sub_signPiece_of_zero hxArg
  exact hLHS.trans hRHS_simp.symm

/-- main lemmas. -/
lemma zeroTemp_target_updNeg_as_ofReal_one_sub_sign
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù] [OrderHomClass F R ‚Ñù]
    (f : F) (hf : Function.Injective f)
    (p : Params NN) (s : NN.State) (u : U) :
    let net := s.net p u
    let Œ∏ := (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u)
    (zeroTempLimitPMF (NN := NN) p s u) (updNeg (s:=s) (u:=u)) =
      ENNReal.ofReal
        (1 - (if 0 < ((scale (NN := NN) (f:=f)) / kB) * (f (net - Œ∏))
              then 1 else if ((scale (NN := NN) (f:=f)) / kB) *
                (f (net - Œ∏)) < 0 then 0 else (1/2 : ‚Ñù))) := by
  intro net Œ∏
  rcases lt_trichotomy Œ∏ net with hpos | hEq | hneg
  ¬∑ -- positive field
    exact zeroTemp_target_updNeg_as_ofReal_one_sub_sign_pos
            (NN := NN) f hf p s u hpos rfl rfl
  ¬∑ -- tie (Œ∏ = net)
    have : net = Œ∏ := hEq.symm
    exact zeroTemp_target_updNeg_as_ofReal_one_sub_sign_tie
            (NN := NN) f hf p s u this rfl rfl
  ¬∑ -- negative field (net < Œ∏)
    exact zeroTemp_target_updNeg_as_ofReal_one_sub_sign_neg
            (NN := NN) f hf p s u hneg rfl rfl

/-- Real-valued limit along `Œ≤ (ofŒ≤ b) = b`: `probPos` tends to 1/0/1/2 by the sign of `c0`. -/
lemma tendsto_probPos_along_ofŒ≤_to_piecewise
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù] [OrderHomClass F R ‚Ñù]
    (f : F) (p : Params NN) (s : NN.State) (u : U) :
    let L := (s.net p u) - (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u)
    let c0 : ‚Ñù := (scale (NN := NN) (f:=f)) * (f L)
    Tendsto (fun b : ‚Ñù‚â•0 => probPos (NN := NN) f p (Temperature.ofŒ≤ b) s u)
      atTop
      (ùìù (if 0 < c0 then 1 else if c0 < 0 then 0 else 1/2)) := by
  intro L c0
  have hŒ≤ : ‚àÄ b, (Œ≤ (Temperature.ofŒ≤ b) : ‚Ñù) = b := by intro b; simp
  have h_form :
      ‚àÄ b, probPos (NN := NN) f p (Temperature.ofŒ≤ b) s u
            = logisticProb (c0 * (b : ‚Ñù)) := by
    intro b; unfold probPos; simp [L, c0, mul_comm, logisticProb]
  simpa [h_form] using tendsto_logistic_const_mul_coeNNReal c0

/-- Convergence on `updPos`: short proof using the split helpers. -/
lemma gibbs_update_tends_to_zero_temp_limit_apply_updPos
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù] [OrderHomClass F R ‚Ñù]
    (f : F) (hf : Function.Injective f)
    (p : Params NN) (s : NN.State) (u : U) :
    Tendsto (fun b : ‚Ñù‚â•0 =>
      (gibbsUpdate (NN := NN) f p (Temperature.ofŒ≤ b) s u) (updPos (s:=s) (u:=u)))
      atTop (ùìù ((zeroTempLimitPMF (NN := NN) p s u) (updPos (s:=s) (u:=u)))) := by
  have h_target := zeroTemp_target_updPos_as_ofReal_sign (NN := NN) f hf p s u
  have hev := eventually_eval_updPos_eq_ofReal_probPos (NN := NN) f p s u
  set net := s.net p u
  set Œ∏ := (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u)
  set L : R := net - Œ∏
  set c0 : ‚Ñù := (scale (NN := NN) (f:=f)) * (f L)
  have h_real := tendsto_probPos_along_ofŒ≤_to_piecewise (NN := NN) f p s u
  have h_rewrite := sign_piecewise_rewrite_with_c0 (R:=R) (U:=U) (œÉ:=œÉ) (NN := NN) (f:=f) L
  have hlim := ENNReal.tendsto_ofReal (by simpa [L, c0, h_rewrite] using h_real)
  have h := (tendsto_congr' hev).mpr hlim
  have h' : Tendsto (fun b : ‚Ñù‚â•0 =>
      (gibbsUpdate (NN := NN) f p (Temperature.ofŒ≤ b) s u) (updPos (s:=s) (u:=u)))
      atTop (ùìù (ENNReal.ofReal
        (if 0 < ((scale (NN := NN) (f:=f)) / kB) * (f (net - Œ∏))
         then 1 else if ((scale (NN := NN) (f:=f)) / kB) * (f (net - Œ∏)) < 0 then 0 else (1/2 : ‚Ñù)))) := by
    simp_all only [one_div, map_sub, net, Œ∏, L]
  simpa [h_target, net, Œ∏] using h'

/-- Convergence on `updNeg`: short proof using the split helpers. -/
lemma gibbs_update_tends_to_zero_temp_limit_apply_updNeg
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù] [OrderHomClass F R ‚Ñù]
    (f : F) (hf : Function.Injective f)
    (p : Params NN) (s : NN.State) (u : U) :
    Tendsto (fun b : ‚Ñù‚â•0 =>
      (gibbsUpdate (NN := NN) f p (Temperature.ofŒ≤ b) s u) (updNeg (s:=s) (u:=u)))
      atTop (ùìù ((zeroTempLimitPMF (NN := NN) p s u) (updNeg (s:=s) (u:=u)))) := by
  have h_target := zeroTemp_target_updNeg_as_ofReal_one_sub_sign (NN := NN) f hf p s u
  have hev := eventually_eval_updNeg_eq_ofReal_one_sub_probPos (NN := NN) f p s u
  set net := s.net p u
  set Œ∏ := (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u)
  set L : R := net - Œ∏
  set c0 : ‚Ñù := (scale (NN := NN) (f:=f)) * (f L)
  have h_real :=
    tendsto_probPos_along_ofŒ≤_to_piecewise (NN := NN) f p s u
  have h_sub :
      Tendsto (fun b : ‚Ñù‚â•0 =>
        (1 : ‚Ñù) - probPos (NN := NN) f p (Temperature.ofŒ≤ b) s u)
        atTop
        (ùìù (1 - (if 0 < c0 then 1 else if c0 < 0 then 0 else (1/2)))) :=
    tendsto_const_nhds.sub h_real
  have h_lift :
      Tendsto (fun b : ‚Ñù‚â•0 =>
        ENNReal.ofReal (1 - probPos (NN := NN) f p (Temperature.ofŒ≤ b) s u))
        atTop
        (ùìù (ENNReal.ofReal (1 - (if 0 < c0 then 1 else if c0 < 0 then 0 else (1/2))))) :=
    ENNReal.tendsto_ofReal h_sub
  have h_rewrite :
      (if 0 < ((scale (NN := NN) (f:=f)) / kB) * (f L) then 1
       else if ((scale (NN := NN) (f:=f)) / kB) * (f L) < 0 then 0 else (1/2 : ‚Ñù))
        =
      (if 0 < c0 then 1 else if c0 < 0 then 0 else (1/2 : ‚Ñù)) := by
    simpa [c0, one_div] using
      sign_piecewise_rewrite_with_c0
        (R:=R) (U:=U) (œÉ:=œÉ) (NN := NN) (f:=f) L
  have h_conv :
      Tendsto (fun b : ‚Ñù‚â•0 =>
        (gibbsUpdate (NN := NN) f p (Temperature.ofŒ≤ b) s u) (updNeg (s:=s) (u:=u)))
        atTop
        (ùìù (ENNReal.ofReal
              (1 - (if 0 < ((scale (NN := NN) (f:=f)) / kB) * (f L)
                     then 1 else if ((scale (NN := NN) (f:=f)) / kB) * (f L) < 0
                                   then 0 else (1/2 : ‚Ñù))))) := by
    have := (tendsto_congr' hev).mpr h_lift
    simp_all only [map_sub, one_div, net, Œ∏, c0, L]
  simp_all only [map_sub, one_div, net, Œ∏, c0, L]

/-- Convergence on any ‚Äúother‚Äù state (neither updPos nor updNeg). -/
lemma gibbs_update_tends_to_zero_temp_limit_apply_other
    {F} [FunLike F R ‚Ñù]
    (f : F)
    (p : Params NN) (s : NN.State) (u : U)
    {state : NN.State}
    (hpos : state ‚â† updPos (s := s) (u := u))
    (hneg : state ‚â† updNeg (s := s) (u := u)) :
    Tendsto (fun b : ‚Ñù‚â•0 =>
      (gibbsUpdate (NN := NN) f p (Temperature.ofŒ≤ b) s u) state)
      atTop (ùìù ((zeroTempLimitPMF (NN := NN) p s u) state)) := by
  set net := s.net p u
  set Œ∏ := (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN := NN) u)
  have htarget0 :
      (zeroTempLimitPMF (NN := NN) p s u) state = 0 := by
    by_cases hŒ∏net : Œ∏ < net
    ¬∑ simp [zeroTempLimitPMF, net, Œ∏, hŒ∏net, PMF.pure_apply, hpos]
    ¬∑ by_cases hnetŒ∏ : net < Œ∏
      ¬∑ simp [zeroTempLimitPMF, net, Œ∏, hŒ∏net, hnetŒ∏, PMF.pure_apply, hneg]
      ¬∑ -- tie case: Œ∏ = net
        -- zeroTempLimitPMF tie branch is the Bernoulli(1/2) mixture over updPos / updNeg.
        have hbind_zero :
          ((PMF.bernoulli (1/2 : ‚Ñù‚â•0) (by norm_num : (1/2 : ‚Ñù‚â•0) ‚â§ 1)) >>= fun b =>
            if b then PMF.pure (updPos (s:=s) (u:=u))
                 else PMF.pure (updNeg (s:=s) (u:=u))) state = 0 :=
          PMF.bernoulli_bind_pure_apply_other
            (Œ±:=NN.State) (by norm_num : (1/2 : ‚Ñù‚â•0) ‚â§ 1) hpos hneg
        simpa [zeroTempLimitPMF, net, Œ∏, hŒ∏net, hnetŒ∏] using hbind_zero
  have hev :
      (fun b : ‚Ñù‚â•0 =>
        (gibbsUpdate (NN := NN) f p (Temperature.ofŒ≤ b) s u) state)
      =·∂†[atTop] (fun _ => (0 : ‚Ñù‚â•0‚àû)) := by
    refine Filter.Eventually.of_forall ?_
    intro b
    -- In the "other state" case the Gibbs PMF assigns zero mass.
    simp [gibbsUpdate, hpos, hneg]
  have : Tendsto (fun b : ‚Ñù‚â•0 =>
      (gibbsUpdate (NN := NN) f p (Temperature.ofŒ≤ b) s u) state)
      atTop (ùìù 0) :=
    (tendsto_congr' hev).mpr tendsto_const_nhds
  simpa [htarget0] using this

/-- **Theorem** Pointwise convergence of the one‚Äìsite Gibbs PMF to the zero-temperature limit PMF,
for every state. This wraps the three evaluation lemmas into a single statement.
The proof proceeds by case analysis on whether
the target state is the positive update, negative update, or some other state, applying
the corresponding specialized convergence results.
-/
theorem gibbs_update_tends_to_zero_temp_limit
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù] [OrderHomClass F R ‚Ñù]
    (f : F) (hf : Function.Injective f)
    (p : Params NN) (s : NN.State) (u : U) :
    ‚àÄ state : NN.State,
      Tendsto (fun b : ‚Ñù‚â•0 =>
        (gibbsUpdate (NN := NN) f p (Temperature.ofŒ≤ b) s u) state)
        atTop (ùìù ((zeroTempLimitPMF (NN := NN) p s u) state)) := by
  intro state
  by_cases hpos : state = updPos (s:=s) (u:=u)
  ¬∑ subst hpos
    exact gibbs_update_tends_to_zero_temp_limit_apply_updPos
            (NN := NN) f hf p s u
  ¬∑ by_cases hneg : state = updNeg (s:=s) (u:=u)
    ¬∑ subst hneg
      exact gibbs_update_tends_to_zero_temp_limit_apply_updNeg
              (NN := NN) f hf p s u
    ¬∑ exact gibbs_update_tends_to_zero_temp_limit_apply_other
              (NN := NN) f p s u (by simpa using hpos) (by simpa using hneg)

end TwoState
